"""æ–‡æ¡£æœåŠ¡ï¼Œå¤„ç†æ–‡æ¡£ä¸Šä¼ ã€è§£æã€LightRAG é›†æˆ"""
import asyncio
import json
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from fastapi import UploadFile

import app.config as config
from app.services.conversation_service import ConversationService
from app.services.lightrag_service import LightRAGService
from app.storage.file_manager import FileManager
from app.utils.document_parser import DocumentParser

# å…¨å±€ä¿¡å·é‡ï¼šé™åˆ¶åŒæ—¶å¤„ç†çš„æ–‡æ¡£æ•°é‡ï¼ˆé¿å… LightRAG å¹¶å‘å†²çªï¼‰
_processing_semaphore = asyncio.Semaphore(1)  # åŒä¸€æ—¶é—´åªå¤„ç†1ä¸ªæ–‡æ¡£
# å¤„ç†é˜Ÿåˆ—é”ï¼šç¡®ä¿é˜Ÿåˆ—æ“ä½œçš„åŸå­æ€§
_queue_lock = asyncio.Lock()
# ç­‰å¾…é˜Ÿåˆ—ï¼š{ conversation_id: [document_id, ...] }
_processing_queue: Dict[str, List[str]] = {}


class DocumentService:
    """æ–‡æ¡£æœåŠ¡"""
    
    def __init__(self):
        self.conversation_service = ConversationService()
        self.lightrag_service = LightRAGService()
        self.file_manager = FileManager()
        self.document_parser = DocumentParser()
        self.status_dir = Path(config.settings.conversations_metadata_dir) / "document_status"
        self.status_dir.mkdir(parents=True, exist_ok=True)
    
    def _clean_base64_and_save(self, text: str, conversation_id: str) -> Tuple[str, Dict[str, str]]:
        """æ¸…ç†æ–‡æœ¬ä¸­çš„ base64 å­—ç¬¦ä¸²ï¼Œä¿å­˜åˆ° base_64.jsonï¼Œå¹¶è¿”å›æ¸…ç†åçš„æ–‡æœ¬å’Œæ˜ å°„å…³ç³»
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            conversation_id: å¯¹è¯ID
            
        Returns:
            (æ¸…ç†åçš„æ–‡æœ¬, base64æ˜ å°„å­—å…¸ {åºå·: base64å­—ç¬¦ä¸²})
        """
        # è·å– base64.json æ–‡ä»¶è·¯å¾„ï¼ˆä¸ kv_store_full_docs.json åŒçº§ï¼‰
        print("cleaning base64", "="*70)
        base_working_dir = Path(config.settings.lightrag_working_dir)
        base64_file = base_working_dir.parent / conversation_id / conversation_id / "base_64.json"
        base64_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å·²æœ‰çš„ base64 æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        base64_map = {}
        if base64_file.exists():
            try:
                with open(base64_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    base64_map = existing_data if isinstance(existing_data, dict) else {}
            except:
                base64_map = {}
        
        # è·å–ä¸‹ä¸€ä¸ªåºå·ï¼ˆä»å·²æœ‰æœ€å¤§åºå·+1å¼€å§‹ï¼‰
        existing_indices = [int(k) for k in base64_map.keys() if k.isdigit()]
        next_index = max(existing_indices, default=0) + 1
        
        cleaned_text = text
        
        # 1. å¤„ç† <latexit> æ ‡ç­¾åŠå…¶å†…å®¹
        # åŒ¹é… <latexit> æ ‡ç­¾ï¼ŒåŒ…æ‹¬æ ‡ç­¾å±æ€§å’Œæ ‡ç­¾å†…å®¹
        latexit_pattern = r'<latexit[^>]*>([^<]*)</latexit>'
        
        def replace_latexit(match):
            nonlocal next_index
            full_match = match.group(0)
            tag_content = match.group(1).strip()
            
            # æå–æ ‡ç­¾ä¸­çš„ sha1_base64 å±æ€§å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            sha1_match = re.search(r'sha1_base64="([^"]+)"', full_match)
            
            # æå–æ ‡ç­¾å†…å®¹ä¸­çš„ base64 å­—ç¬¦ä¸²ï¼ˆé€šå¸¸æ˜¯é•¿å­—ç¬¦ä¸²ï¼‰
            base64_in_content = re.search(r'[A-Za-z0-9+/=]{50,}', tag_content)
            
            # ä¼˜å…ˆä½¿ç”¨æ ‡ç­¾å†…å®¹ä¸­çš„ base64ï¼Œå¦åˆ™ä½¿ç”¨ sha1_base64 å±æ€§
            if base64_in_content:
                base64_value = base64_in_content.group(0)
            elif sha1_match:
                base64_value = sha1_match.group(1)
            elif tag_content and len(tag_content) > 20:
                base64_value = tag_content
            else:
                return ""  # å¦‚æœå†…å®¹å¤ªçŸ­æˆ–æ²¡æœ‰ base64ï¼Œç›´æ¥ç§»é™¤
            
            index_str = str(next_index)
            base64_map[index_str] = base64_value
            next_index += 1
            return f"[BASE64_{index_str}]"
        
        cleaned_text = re.sub(latexit_pattern, replace_latexit, cleaned_text, flags=re.DOTALL)
        
        # 2. å¤„ç†ç‹¬ç«‹çš„ base64 å­—ç¬¦ä¸²ï¼ˆé•¿åº¦>=50ï¼Œä¸”ä¸åœ¨å·²æ›¿æ¢çš„å¼•ç”¨ä¸­ï¼‰
        # å…ˆæ ‡è®°å·²æ›¿æ¢çš„ä½ç½®ï¼Œé¿å…é‡å¤å¤„ç†
        standalone_base64_pattern = r'(?<!\[BASE64_)[A-Za-z0-9+/=]{50,}(?!\])'
        
        def replace_standalone(match):
            nonlocal next_index
            base64_str = match.group(0)
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ base64ï¼ˆä¸åŒ…å«ç©ºæ ¼ã€æ¢è¡Œç­‰ï¼‰
            if re.match(r'^[A-Za-z0-9+/=]+$', base64_str):
                index_str = str(next_index)
                base64_map[index_str] = base64_str
                next_index += 1
                return f"[BASE64_{index_str}]"
            return base64_str
        
        cleaned_text = re.sub(standalone_base64_pattern, replace_standalone, cleaned_text)
        
        # ä¿å­˜ base64 æ˜ å°„åˆ°æ–‡ä»¶ï¼ˆå¦‚æœæœ‰æ–°å¢ï¼‰
        if base64_map:
            with open(base64_file, 'w', encoding='utf-8') as f:
                json.dump(base64_map, f, ensure_ascii=False, indent=2)
        
        return cleaned_text, base64_map
    
    def _get_status_file(self, conversation_id: str) -> Path:
        """è·å–çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
        return self.status_dir / f"{conversation_id}.json"
    
    def _load_status(self, conversation_id: str) -> Dict:
        """åŠ è½½æ–‡æ¡£çŠ¶æ€"""
        status_file = self._get_status_file(conversation_id)
        if status_file.exists():
            try:
                with open(status_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {"documents": {}}
        return {"documents": {}}
    
    def _save_status(self, conversation_id: str, status: Dict):
        """ä¿å­˜æ–‡æ¡£çŠ¶æ€"""
        status_file = self._get_status_file(conversation_id)
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump(status, f, ensure_ascii=False, indent=2)
    
    def _validate_file(self, filename: str) -> tuple[bool, Optional[str]]:
        """éªŒè¯æ–‡ä»¶ç±»å‹
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        file_ext = Path(filename).suffix.lower().lstrip('.')
        if file_ext not in config.settings.allowed_extensions:
            return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}ï¼Œä»…æ”¯æŒ {', '.join(config.settings.allowed_extensions)}"
        
        return True, None
    
    async def _check_file_size(self, file_content: bytes) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥æ–‡ä»¶å¤§å°
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        file_size = len(file_content)
        
        if file_size > config.settings.max_file_size:
            return False, f"æ–‡ä»¶å¤§å° {file_size / 1024 / 1024:.2f}MB è¶…è¿‡é™åˆ¶ {config.settings.max_file_size / 1024 / 1024}MB"
        
        return True, None
    
    async def upload_documents(self, conversation_id: Optional[str], files: List[UploadFile]) -> Dict:
        """ä¸Šä¼ æ–‡æ¡£åˆ°å¯¹è¯
        
        Args:
            conversation_id: å¯¹è¯IDï¼ˆå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»ºï¼‰
            files: æ–‡ä»¶åˆ—è¡¨ï¼ˆUploadFile å¯¹è±¡ï¼‰
            
        Returns:
            ä¸Šä¼ ç»“æœå­—å…¸
        """
        # è‡ªåŠ¨åˆ›å»ºå¯¹è¯ï¼ˆå¦‚æœ conversation_id ä¸º None æˆ– "new"ï¼‰
        if conversation_id is None or conversation_id == "new":
            # åŸºäºç¬¬ä¸€ä¸ªæ–‡ä»¶åç”Ÿæˆå¯¹è¯æ ‡é¢˜ï¼ˆå¯é€‰ï¼Œå¦‚ä¸æä¾›åˆ™ä½¿ç”¨è‡ªåŠ¨ç¼–å·ï¼‰
            first_filename = files[0].filename if files else "æ–°å¯¹è¯"
            title = Path(first_filename).stem if files else None
            conversation_id = self.conversation_service.create_conversation(title=title)
        
        # éªŒè¯å¯¹è¯æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
        conversation = self.conversation_service.get_conversation(conversation_id)
        if not conversation:
            # å¯¹è¯ä¸å­˜åœ¨æ—¶è‡ªåŠ¨åˆ›å»º
            conversation_id = self.conversation_service.create_conversation(title=None)
            conversation = self.conversation_service.get_conversation(conversation_id)
        
        # æ£€æŸ¥å½“å‰æ–‡ä»¶æ•°é‡
        status = self._load_status(conversation_id)
        current_file_count = len(status.get("documents", {}))
        
        if current_file_count + len(files) > config.settings.max_files_per_conversation:
            raise ValueError(
                f"å¯¹è¯å·²æœ‰ {current_file_count} ä¸ªæ–‡ä»¶ï¼Œå†ä¸Šä¼  {len(files)} ä¸ªå°†è¶…è¿‡é™åˆ¶ "
                f"({config.settings.max_files_per_conversation} ä¸ª)"
            )
        
        uploaded_files = []
        
        for file in files:
            # éªŒè¯æ–‡ä»¶ç±»å‹
            is_valid, error_msg = self._validate_file(file.filename)
            if not is_valid:
                raise ValueError(error_msg)
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            file_content = await file.read()
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            is_valid, error_msg = await self._check_file_size(file_content)
            if not is_valid:
                raise ValueError(error_msg)
            
            # ä¿å­˜æ–‡ä»¶
            file_info = self.file_manager.save_file(
                conversation_id=conversation_id,
                file_content=file_content,
                original_filename=file.filename
            )
            
            # åˆ›å»ºæ–‡æ¡£è®°å½•
            document_id = file_info["file_id"]
            now = datetime.utcnow().isoformat() + "Z"
            
            document_data = {
                "file_id": document_id,
                "conversation_id": conversation_id,
                "filename": file.filename,
                "file_size": file_info["file_size"],
                "file_extension": file_info["file_extension"],
                "file_path": file_info["file_path"],
                "upload_time": now,
                "status": "pending",
                "lightrag_track_id": None,
            }
            
            # æ›´æ–°çŠ¶æ€
            status = self._load_status(conversation_id)
            if "documents" not in status:
                status["documents"] = {}
            status["documents"][document_id] = document_data
            self._save_status(conversation_id, status)
            
            # æ›´æ–°å¯¹è¯æ–‡ä»¶è®¡æ•°
            self.conversation_service.increment_file_count(conversation_id)
            
            uploaded_files.append({
                "file_id": document_id,
                "filename": file.filename,
                "file_size": file_info["file_size"],
                "status": "pending"
            })
        
        return {
            "conversation_id": conversation_id,
            "uploaded_files": uploaded_files,
            "total_files": len(uploaded_files)
        }
    
    async def process_document(self, conversation_id: str, document_id: str):
        """å¤„ç†æ–‡æ¡£ï¼šè§£ææ–‡æœ¬å¹¶æ’å…¥ LightRAGï¼ˆå¼‚æ­¥åå°ä»»åŠ¡ï¼‰
        
        ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘ï¼Œç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªæ–‡æ¡£åœ¨å¤„ç†ï¼Œ
        é¿å… LightRAG å¹¶å‘å†™å…¥å†²çªã€‚
        
        Args:
            conversation_id: å¯¹è¯ID
            document_id: æ–‡æ¡£ID
        """
        global _processing_queue
        
        # å°†æ–‡æ¡£åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        async with _queue_lock:
            if conversation_id not in _processing_queue:
                _processing_queue[conversation_id] = []
            if document_id not in _processing_queue[conversation_id]:
                _processing_queue[conversation_id].append(document_id)
            queue_position = _processing_queue[conversation_id].index(document_id) + 1
            print(f"ğŸ“‹ æ–‡æ¡£ {document_id[:8]}... åŠ å…¥é˜Ÿåˆ—ï¼Œä½ç½®: {queue_position}")
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘ï¼ˆåŒä¸€æ—¶é—´åªå¤„ç†1ä¸ªæ–‡æ¡£ï¼‰
        async with _processing_semaphore:
            print(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡æ¡£: {document_id[:8]}...")
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            status = self._load_status(conversation_id)
            if document_id in status.get("documents", {}):
                status["documents"][document_id]["status"] = "processing"
                self._save_status(conversation_id, status)
            
            try:
                # è·å–æ–‡ä»¶è·¯å¾„
                file_path = self.file_manager.get_file_path(conversation_id, document_id)
                if not file_path or not file_path.exists():
                    raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {document_id}")
                
                # è§£ææ–‡æ¡£ï¼Œæå–æ–‡æœ¬
                text = self.document_parser.extract_text(str(file_path))
                
                if not text or not text.strip():
                    raise ValueError("æ–‡æ¡£è§£æåæ–‡æœ¬å†…å®¹ä¸ºç©º")
                
                # æ¸…ç† base64 å­—ç¬¦ä¸²å¹¶ä¿å­˜
                cleaned_text, base64_map = self._clean_base64_and_save(text, conversation_id)
                
                # æ’å…¥åˆ° LightRAGï¼ˆä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬ï¼‰
                track_id = await self.lightrag_service.insert_document(
                    conversation_id=conversation_id,
                    text=cleaned_text,
                    doc_id=document_id
                )
                
                # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
                status = self._load_status(conversation_id)
                if document_id in status.get("documents", {}):
                    status["documents"][document_id]["status"] = "completed"
                    status["documents"][document_id]["lightrag_track_id"] = track_id
                    self._save_status(conversation_id, status)
                
                print(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {document_id[:8]}...")
            
            except Exception as e:
                # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                status = self._load_status(conversation_id)
                if document_id in status.get("documents", {}):
                    status["documents"][document_id]["status"] = "failed"
                    status["documents"][document_id]["error"] = str(e)
                    self._save_status(conversation_id, status)
                print(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {document_id[:8]}... é”™è¯¯: {e}")
                raise
            finally:
                # ä»é˜Ÿåˆ—ä¸­ç§»é™¤
                async with _queue_lock:
                    if conversation_id in _processing_queue:
                        if document_id in _processing_queue[conversation_id]:
                            _processing_queue[conversation_id].remove(document_id)
                        if not _processing_queue[conversation_id]:
                            del _processing_queue[conversation_id]
    
    def get_document(self, conversation_id: str, file_id: str) -> Optional[Dict]:
        """è·å–æ–‡æ¡£ä¿¡æ¯
        
        Args:
            conversation_id: å¯¹è¯ID
            file_id: æ–‡ä»¶ID
            
        Returns:
            æ–‡æ¡£ä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        status = self._load_status(conversation_id)
        return status.get("documents", {}).get(file_id)
    
    def list_documents(self, conversation_id: str) -> List[Dict]:
        """åˆ—å‡ºå¯¹è¯çš„æ‰€æœ‰æ–‡æ¡£
        
        Args:
            conversation_id: å¯¹è¯ID
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        status = self._load_status(conversation_id)
        documents = list(status.get("documents", {}).values())
        # æŒ‰ä¸Šä¼ æ—¶é—´å€’åºæ’åˆ—
        documents.sort(key=lambda x: x.get("upload_time", ""), reverse=True)
        return documents
    
    async def get_document_status(self, conversation_id: str, file_id: str) -> Optional[Dict]:
        """è·å–æ–‡æ¡£å¤„ç†çŠ¶æ€
        
        Args:
            conversation_id: å¯¹è¯ID
            file_id: æ–‡ä»¶ID
            
        Returns:
            æ–‡æ¡£çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…å«è¿›åº¦ä¿¡æ¯
        """
        document = self.get_document(conversation_id, file_id)
        if document:
            status_info = {
                "file_id": file_id,
                "status": document.get("status"),
                "lightrag_track_id": document.get("lightrag_track_id"),
                "error": document.get("error"),
                "upload_time": document.get("upload_time"),
            }
            
            # å¦‚æœæ–‡æ¡£æ­£åœ¨å¤„ç†ä¸­ï¼Œå°è¯•è·å–è¿›åº¦ä¿¡æ¯
            if document.get("status") == "processing":
                try:
                    progress = await self.lightrag_service.get_processing_progress(doc_id=file_id)
                    if progress:
                        status_info["progress"] = progress
                except Exception:
                    # å¦‚æœè·å–è¿›åº¦å¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯
                    pass
            
            return status_info
        return None
    
    async def delete_document(self, conversation_id: str, file_id: str) -> bool:
        """åˆ é™¤æ–‡æ¡£
        
        åˆ é™¤æ“ä½œåŒ…æ‹¬ï¼š
        1. ä»æ–‡ä»¶ç³»ç»Ÿåˆ é™¤æ–‡ä»¶
        2. ä»LightRAGçŸ¥è¯†å›¾è°±ä¸­åˆ é™¤ç›¸å…³æ•°æ®
        3. æ¸…ç†å›¾ç‰‡ç¼“å­˜
        4. ä»çŠ¶æ€ä¸­åˆ é™¤è®°å½•
        5. æ›´æ–°å¯¹è¯æ–‡ä»¶è®¡æ•°
        
        Args:
            conversation_id: å¯¹è¯ID
            file_id: æ–‡ä»¶ID
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        # è·å–æ–‡æ¡£ä¿¡æ¯ï¼ˆç”¨äºæ¸…ç†ç¼“å­˜å’ŒLightRAGæ•°æ®ï¼‰
        document = self.get_document(conversation_id, file_id)
        
        if not document:
            return False
        
        try:
            # 1. ä»LightRAGä¸­åˆ é™¤æ–‡æ¡£æ•°æ®ï¼ˆå¦‚æœå·²å¤„ç†ï¼‰
            if document.get("status") == "completed" and document.get("lightrag_track_id"):
                try:
                    # è·å–LightRAGå®ä¾‹å¹¶åˆ é™¤æ–‡æ¡£
                    lightrag = await self.lightrag_service.get_lightrag_for_conversation(conversation_id)
                    # LightRAGå¯èƒ½æ²¡æœ‰ç›´æ¥çš„åˆ é™¤æ–¹æ³•ï¼Œè¿™é‡Œå…ˆå°è¯•åˆ é™¤ç›¸å…³çš„chunks
                    # æ³¨æ„ï¼šLightRAGå¯èƒ½æ²¡æœ‰æä¾›åˆ é™¤å•ä¸ªæ–‡æ¡£çš„APIï¼Œéœ€è¦æŸ¥çœ‹æ–‡æ¡£
                    # æš‚æ—¶è·³è¿‡ï¼Œå› ä¸ºLightRAGçš„è®¾è®¡å¯èƒ½æ˜¯ä¸å¯é€†çš„
                    pass
                except Exception as e:
                    # LightRAGåˆ é™¤å¤±è´¥ä¸å½±å“æ–‡ä»¶åˆ é™¤ï¼Œè®°å½•æ—¥å¿—å³å¯
                    print(f"Warning: ä»LightRAGåˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            
            # 2. æ¸…ç†å›¾ç‰‡ç¼“å­˜
            try:
                from app.utils.image_renderer import ImageRenderer
                import app.config as config
                
                image_renderer = ImageRenderer(
                    cache_dir=config.settings.image_cache_dir,
                    resolution=config.settings.image_resolution,
                    cache_expiry_hours=config.settings.image_cache_expiry_hours
                )
                
                file_ext = document.get("file_extension", "")
                if file_ext:
                    # åˆ é™¤è¯¥æ–‡ä»¶çš„æ‰€æœ‰ç¼“å­˜å›¾ç‰‡ï¼ˆåŒ…æ‹¬ç¼©ç•¥å›¾ï¼‰
                    cache_dir = Path(config.settings.image_cache_dir) / file_ext / file_id
                    if cache_dir.exists():
                        import shutil
                        shutil.rmtree(cache_dir, ignore_errors=True)
            except Exception as e:
                # ç¼“å­˜æ¸…ç†å¤±è´¥ä¸å½±å“æ–‡ä»¶åˆ é™¤
                print(f"Warning: æ¸…ç†å›¾ç‰‡ç¼“å­˜å¤±è´¥: {e}")
            
            # 3. åˆ é™¤æ–‡ä»¶
            file_deleted = self.file_manager.delete_file(conversation_id, file_id)
            
            # 4. ä»çŠ¶æ€ä¸­åˆ é™¤
            if file_id in self._load_status(conversation_id).get("documents", {}):
                status = self._load_status(conversation_id)
                del status["documents"][file_id]
                self._save_status(conversation_id, status)
            
            # 5. æ›´æ–°å¯¹è¯æ–‡ä»¶è®¡æ•°
            self.conversation_service.decrement_file_count(conversation_id)
            
            return file_deleted
            
        except Exception as e:
            print(f"Error deleting document {file_id}: {e}")
            # å³ä½¿éƒ¨åˆ†æ“ä½œå¤±è´¥ï¼Œä¹Ÿå°è¯•åˆ é™¤æ–‡ä»¶
            return self.file_manager.delete_file(conversation_id, file_id)
