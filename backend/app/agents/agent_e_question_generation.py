# -*- coding: utf-8 -*-
# ===========================================================
# æ–‡ä»¶ï¼šbackend/app/agents/agent_e_question_generation.py
# åŠŸèƒ½ï¼šAgent E â€“ æ™ºèƒ½å‡ºé¢˜ç”Ÿæˆï¼ˆé«˜ä¿çœŸä»¿çœŸç‰ˆï¼Œæœ€å°å·®å¼‚ä¿®æ­£ç‰ˆï¼‰
# ===========================================================

import os
import json
import re
import aiohttp
import asyncio
from dotenv import load_dotenv
from app.agents.shared_state import shared_state
from app.agents.models.quiz_models import Question, QuestionBank, SubQuestion
from app.agents.database.question_bank_storage import save_question_bank, BASE_DATA_DIR

# -----------------------------------------------------------
# ç¯å¢ƒé…ç½®
# -----------------------------------------------------------

load_dotenv()
API_URL = os.getenv("LLM_BINDING_HOST", "https://api.siliconflow.cn/v1")
API_KEY = os.getenv("LLM_BINDING_API_KEY")
MODEL_NAME = os.getenv("LLM_MODEL", "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B")

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
}


def _save_llm_response(conversation_id: str, section_name: str, prompt: str, response: str):
    """ä¿å­˜ LLM çš„å®Œæ•´è¯·æ±‚å’Œå“åº”åˆ° debug ç›®å½•"""
    debug_dir = os.path.join(BASE_DATA_DIR, conversation_id, "debug")
    os.makedirs(debug_dir, exist_ok=True)
    
    # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
    safe_section = re.sub(r'[\\/:*?"<>|]', '_', section_name)
    file_path = os.path.join(debug_dir, f"agent_e_{safe_section}_response.txt")
    
    with open(file_path, "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write(f"Section: {section_name}\n")
        f.write("=" * 80 + "\n\n")
        f.write("ã€å‘é€çš„ Promptã€‘\n")
        f.write("-" * 40 + "\n")
        f.write(prompt)
        f.write("\n\n")
        f.write("ã€LLM åŸå§‹å“åº”ã€‘\n")
        f.write("-" * 40 + "\n")
        f.write(response)
        f.write("\n")
    
    print(f"ğŸ“ LLM å“åº”å·²ä¿å­˜ï¼š{file_path}")

def _has_cjk(s: str) -> bool:
    import re
    return bool(re.search(r"[\u4e00-\u9fff]", s or ""))

def _detect_language_from_stem(stem: str) -> str:
    return "Chinese" if _has_cjk(stem or "") else "English"


def _format_sub_questions(sub_questions, indent=1) -> str:
    """é€’å½’æ ¼å¼åŒ–å­é¢˜ç›®ä¸ºæ–‡æœ¬ï¼Œä¾› Prompt ä½¿ç”¨"""
    if not sub_questions:
        return ""
    
    lines = []
    prefix = "  " * indent
    for sq in sub_questions:
        label = sq.label if hasattr(sq, 'label') else sq.get('label', '')
        stem = sq.stem if hasattr(sq, 'stem') else sq.get('stem', '')
        kps = sq.knowledge_points if hasattr(sq, 'knowledge_points') else sq.get('knowledge_points', [])
        difficulty = sq.difficulty if hasattr(sq, 'difficulty') else sq.get('difficulty', 'medium')
        nested = sq.sub_questions if hasattr(sq, 'sub_questions') else sq.get('sub_questions', [])
        
        lines.append(f"{prefix}({label}) {stem}")
        if kps:
            lines.append(f"{prefix}    çŸ¥è¯†ç‚¹: {', '.join(kps)}")
        if difficulty:
            lines.append(f"{prefix}    éš¾åº¦: {difficulty}")
        
        # é€’å½’å¤„ç†åµŒå¥—å­é¢˜
        if nested:
            lines.append(_format_sub_questions(nested, indent + 1))
    
    return "\n".join(lines)


def _sub_questions_to_json_example(sub_questions) -> list:
    """å°†å­é¢˜ç›®è½¬æ¢ä¸º JSON ç¤ºä¾‹ç»“æ„"""
    if not sub_questions:
        return []
    
    result = []
    for sq in sub_questions:
        label = sq.label if hasattr(sq, 'label') else sq.get('label', '')
        stem = sq.stem if hasattr(sq, 'stem') else sq.get('stem', '')
        kps = sq.knowledge_points if hasattr(sq, 'knowledge_points') else sq.get('knowledge_points', [])
        difficulty = sq.difficulty if hasattr(sq, 'difficulty') else sq.get('difficulty', 'medium')
        qtype = sq.question_type if hasattr(sq, 'question_type') else sq.get('question_type', 'short_answer')
        nested = sq.sub_questions if hasattr(sq, 'sub_questions') else sq.get('sub_questions', [])
        
        item = {
            "label": label,
            "stem": stem,
            "knowledge_points": kps,
            "difficulty": difficulty,
            "question_type": qtype,
        }
        if nested:
            item["sub_questions"] = _sub_questions_to_json_example(nested)
        result.append(item)
    
    return result


def _parse_sub_questions_from_dict(sub_list: list) -> list:
    """ä» LLM è¿”å›çš„å­—å…¸åˆ—è¡¨è§£æä¸º SubQuestion å¯¹è±¡åˆ—è¡¨"""
    if not sub_list or not isinstance(sub_list, list):
        return []
    
    result = []
    for item in sub_list:
        if not isinstance(item, dict):
            continue
        
        label = str(item.get("label", "")).strip()
        stem = str(item.get("stem", "")).strip()
        if not stem:
            continue
        
        # é€’å½’è§£æåµŒå¥—å­é¢˜
        nested = _parse_sub_questions_from_dict(item.get("sub_questions", []))
        
        sq = SubQuestion(
            label=label or "sub",
            stem=stem,
            score=int(item.get("score", 0)) if item.get("score") else 0,
            question_type=str(item.get("question_type", "short_answer")),
            difficulty=str(item.get("difficulty", "medium")),
            knowledge_points=item.get("knowledge_points", []) or ["é€šç”¨çŸ¥è¯†"],
            sub_questions=nested
        )
        result.append(sq)
    
    return result

def _extract_json_array(text: str):
    """ä» LLM è¾“å‡ºä¸­æå– JSON æ•°ç»„ï¼Œæ”¯æŒåµŒå¥—ç»“æ„ï¼ˆå¦‚ sub_questionsï¼‰"""
    if not text:
        return []
    
    text = text.strip()
    
    def _safe_parse(candidate: str):
        """å°è¯•è§£æ JSONï¼Œå¤„ç†å¸¸è§çš„ LaTeX è½¬ä¹‰é—®é¢˜"""
        fixed = candidate
        
        # ä¿®å¤ LaTeX ä¸­å¸¸è§çš„éæ³• JSON è½¬ä¹‰
        # \{ \} \( \) åœ¨ LaTeX ä¸­æ˜¯åˆæ³•çš„ï¼Œä½†åœ¨ JSON ä¸­éœ€è¦åŒåæ–œæ 
        # æ³¨æ„ï¼šåªåœ¨å­—ç¬¦ä¸²å€¼å†…éƒ¨å¤„ç†ï¼Œä¸å½±å“ JSON ç»“æ„
        latex_escapes = [
            (r'\{', r'\\{'),
            (r'\}', r'\\}'),
            (r'\(', r'\\('),
            (r'\)', r'\\)'),
            (r'\[', r'\\['),
            (r'\]', r'\\]'),
            (r'\_', r'\\_'),
            (r'\^', r'\\^'),
            (r'\&', r'\\&'),
            (r'\%', r'\\%'),
            (r'\$', r'\\$'),
            (r'\#', r'\\#'),
        ]
        
        for old, new in latex_escapes:
            # é¿å…é‡å¤è½¬ä¹‰ï¼ˆå¦‚æœå·²ç»æ˜¯ \\ å¼€å¤´å°±è·³è¿‡ï¼‰
            fixed = re.sub(r'(?<!\\)' + re.escape(old), new, fixed)
        
        return json.loads(fixed)
    
    def _find_balanced_json_array(s: str, start_pos: int = 0) -> str:
        """ä½¿ç”¨æ‹¬å·åŒ¹é…æ‰¾åˆ°å®Œæ•´çš„ JSON æ•°ç»„"""
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ª [
        arr_start = s.find('[', start_pos)
        if arr_start == -1:
            return None
        
        bracket_count = 0
        brace_count = 0
        in_string = False
        escape_next = False
        
        for i in range(arr_start, len(s)):
            char = s[i]
            
            if escape_next:
                escape_next = False
                continue
            
            if char == '\\':
                escape_next = True
                continue
            
            if char == '"':
                in_string = not in_string
                continue
            
            if not in_string:
                if char == '[':
                    bracket_count += 1
                elif char == ']':
                    bracket_count -= 1
                    if bracket_count == 0:
                        return s[arr_start:i+1]
                elif char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
        
        return None
    
    # 1. å°è¯•æå– ```json ... ``` ä»£ç å—
    code_block_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
    if code_block_match:
        block_content = code_block_match.group(1).strip()
        json_str = _find_balanced_json_array(block_content)
        if json_str:
            try:
                return _safe_parse(json_str)
            except json.JSONDecodeError:
                pass
    
    # 2. ç›´æ¥åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾ JSON æ•°ç»„
    json_str = _find_balanced_json_array(text)
    if json_str:
        try:
            return _safe_parse(json_str)
        except json.JSONDecodeError as e:
            print(f"[âš ï¸ JSON è§£æå¤±è´¥] {e}")
            # å°è¯•ä¿®å¤å¸¸è§é—®é¢˜åé‡è¯•
            try:
                # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨é€—å·
                fixed = re.sub(r',\s*}', '}', json_str)
                fixed = re.sub(r',\s*]', ']', fixed)
                return _safe_parse(fixed)
            except:
                pass
    
    # 3. å…¨è§’æ‹¬å·è½¬åŠè§’åé‡è¯•
    txt2 = text.replace("ã€", "[").replace("ã€‘", "]")
    json_str = _find_balanced_json_array(txt2)
    if json_str:
        try:
            return _safe_parse(json_str)
        except:
            pass
    
    # 4. å°è¯•è§£æå•ä¸ªå¯¹è±¡
    brace_start = text.find('{')
    if brace_start != -1:
        brace_count = 0
        in_string = False
        escape_next = False
        for i in range(brace_start, len(text)):
            char = text[i]
            if escape_next:
                escape_next = False
                continue
            if char == '\\':
                escape_next = True
                continue
            if char == '"':
                in_string = not in_string
                continue
            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        try:
                            return [_safe_parse(text[brace_start:i+1])]
                        except:
                            break
    
    return []


def _convert_html_table_to_markdown(html_text: str) -> str:
    """å°†HTMLè¡¨æ ¼è½¬æ¢ä¸ºMarkdownè¡¨æ ¼æ ¼å¼ï¼Œä¾›LLMç†è§£"""
    if not html_text or '<table' not in html_text.lower():
        return html_text
    
    result = html_text
    # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
    table_pattern = re.compile(r'<table[^>]*>(.*?)</table>', re.DOTALL | re.IGNORECASE)
    
    for table_match in table_pattern.finditer(html_text):
        table_html = table_match.group(0)
        table_content = table_match.group(1)
        
        # æå–æ‰€æœ‰è¡Œ
        rows = re.findall(r'<tr[^>]*>(.*?)</tr>', table_content, re.DOTALL | re.IGNORECASE)
        if not rows:
            continue
        
        markdown_rows = []
        for i, row in enumerate(rows):
            # æå–å•å…ƒæ ¼
            cells = re.findall(r'<t[hd][^>]*>(.*?)</t[hd]>', row, re.DOTALL | re.IGNORECASE)
            if cells:
                # æ¸…ç†å•å…ƒæ ¼å†…å®¹
                clean_cells = []
                for cell in cells:
                    cell_text = re.sub(r'<[^>]+>', '', cell)
                    cell_text = ' '.join(cell_text.split())
                    clean_cells.append(cell_text)
                
                # æ„å»ºMarkdownè¡Œ
                markdown_rows.append('| ' + ' | '.join(clean_cells) + ' |')
                
                # ç¬¬ä¸€è¡Œåæ·»åŠ åˆ†éš”ç¬¦
                if i == 0:
                    markdown_rows.append('| ' + ' | '.join(['---'] * len(clean_cells)) + ' |')
        
        # æ›¿æ¢åŸHTMLè¡¨æ ¼
        if markdown_rows:
            markdown_table = '\n' + '\n'.join(markdown_rows) + '\n'
            result = result.replace(table_html, markdown_table)
    
    return result


def _convert_markdown_table_to_html(markdown_text: str) -> str:
    """å°†Markdownè¡¨æ ¼è½¬æ¢ä¸ºHTMLè¡¨æ ¼æ ¼å¼ï¼Œç”¨äºä¿å­˜å’Œæ˜¾ç¤º"""
    if not markdown_text or '|' not in markdown_text:
        return markdown_text
    
    result = markdown_text
    # åŒ¹é…Markdownè¡¨æ ¼
    # æ ¼å¼ï¼š| Header | Header |\n|--------|--------|\n| Cell | Cell |
    table_pattern = re.compile(
        r'(\|.+\|\n\|[\s\-:]+\|\n(?:\|.+\|\n?)+)',
        re.MULTILINE
    )
    
    for table_match in table_pattern.finditer(markdown_text):
        markdown_table = table_match.group(0)
        lines = [line.strip() for line in markdown_table.split('\n') if line.strip()]
        
        if len(lines) < 2:
            continue
        
        # ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
        header_cells = [cell.strip() for cell in lines[0].split('|') if cell.strip()]
        
        # ç¬¬äºŒè¡Œæ˜¯åˆ†éš”ç¬¦ï¼Œè·³è¿‡
        # å…¶ä½™è¡Œæ˜¯æ•°æ®
        data_rows = []
        for line in lines[2:]:
            cells = [cell.strip() for cell in line.split('|') if cell.strip()]
            if cells:
                data_rows.append(cells)
        
        # æ„å»ºHTMLè¡¨æ ¼
        html_parts = ['<table>']
        
        # è¡¨å¤´
        html_parts.append('<tr>')
        for cell in header_cells:
            html_parts.append(f'<td>{cell}</td>')
        html_parts.append('</tr>')
        
        # æ•°æ®è¡Œ
        for row_cells in data_rows:
            html_parts.append('<tr>')
            for cell in row_cells:
                html_parts.append(f'<td>{cell}</td>')
            html_parts.append('</tr>')
        
        html_parts.append('</table>')
        
        html_table = ''.join(html_parts)
        result = result.replace(markdown_table, html_table)
    
    return result


async def _generate_answer_for_table_question(session, question_id: str, stem: str) -> str:
    """ä¸ºåŒ…å«è¡¨æ ¼çš„é¢˜ç›®ç”Ÿæˆç­”æ¡ˆ"""
    if '<table' not in stem:
        return None
    
    # å°†HTMLè¡¨æ ¼è½¬ä¸ºMarkdownä¾›LLMç†è§£
    stem_for_llm = _convert_html_table_to_markdown(stem)
    
    prompt = f"""è¯·ä¸ºä»¥ä¸‹é¢˜ç›®æä¾›è¯¦ç»†çš„ç­”æ¡ˆã€‚é¢˜ç›®åŒ…å«è¡¨æ ¼æ•°æ®ï¼Œè¯·ä»”ç»†åˆ†æè¡¨æ ¼ä¸­çš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚

é¢˜ç›®ï¼š
{stem_for_llm}

è¦æ±‚ï¼š
1. å¦‚æœé¢˜ç›®æœ‰å¤šä¸ªå­é—®é¢˜(a)(b)(c)ç­‰ï¼Œè¯·åˆ†åˆ«ä½œç­”
2. å¯¹äºè®¡ç®—é¢˜ï¼Œç»™å‡ºè®¡ç®—æ­¥éª¤å’Œæœ€ç»ˆç»“æœ
3. å¯¹äºåˆ†æé¢˜ï¼Œç»™å‡ºæ¸…æ™°çš„åˆ†ææ€è·¯å’Œç»“è®º
4. ç­”æ¡ˆè¦ç®€æ´æ˜ç¡®ï¼Œé‡ç‚¹çªå‡ºå…³é”®æ­¥éª¤å’Œç»“è®º
5. ä½¿ç”¨ä¸­æ–‡ä½œç­”

è¯·ç›´æ¥è¾“å‡ºç­”æ¡ˆï¼Œä¸è¦é‡å¤é¢˜ç›®ï¼š
"""
    
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åæ•°æ®æŒ–æ˜å’Œæœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸“å®¶ï¼Œæ“…é•¿è§£ç­”ç®—æ³•ã€æ•°å­¦è®¡ç®—å’Œæ•°æ®åˆ†æç›¸å…³çš„é—®é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 2000,
        "temperature": 0.3,
    }
    
    try:
        print(f"[â†’] æ­£åœ¨ä¸ºè¡¨æ ¼é¢˜ç›® {question_id} ç”Ÿæˆç­”æ¡ˆ...")
        async with session.post(f"{API_URL}/chat/completions", headers=HEADERS, json=payload, timeout=300) as resp:
            res = await resp.json()
            if "error" in res:
                print(f"âŒ APIé”™è¯¯: {res['error']}")
                return None
            
            if "choices" not in res or len(res["choices"]) == 0:
                print(f"âŒ å“åº”æ ¼å¼é”™è¯¯")
                return None
            
            answer = res["choices"][0]["message"]["content"].strip()
            print(f"âœ… è¡¨æ ¼é¢˜ç›® {question_id} ç­”æ¡ˆå·²ç”Ÿæˆ (é•¿åº¦: {len(answer)})")
            return answer
    except Exception as e:
        print(f"âŒ è¡¨æ ¼é¢˜ç›® {question_id} ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
        return None


# -----------------------------------------------------------
# Prompt æ„é€ 
# -----------------------------------------------------------

def build_prompt(section, distribution_model, examples=None, global_difficulty="medium",
                 expected_count=None, expected_type=None, expected_kps=None,
                 target_difficulty_hint="ä¿æŒä¸æ ·ä¾‹ç›¸åŒå±‚çº§ï¼Œä½†åœ¨æ·±åº¦ä¸ç»¼åˆæ€§ä¸Šæé«˜",
                 min_subparts=2,expected_language=None):
    """
    æ„é€ é«˜ä¿çœŸå‡ºé¢˜ Promptï¼š
    - é¢˜é‡/é¢˜å‹ç¡¬çº¦æŸ
    - çŸ¥è¯†ç‚¹å¿…å«æ¸…å•
    - æ·±åº¦è¦æ±‚ï¼ˆå¤šæ­¥å­é—®ã€å®šé‡åˆ†æã€è¾¹ç•Œ/å¯¹æ¯”ï¼‰
    """
    type_info = distribution_model.get("type_distribution", {})
    diff_info = distribution_model.get("difficulty_distribution", {})
    kp_info   = distribution_model.get("knowledge_point_distribution", {})

    prompt = f"""
ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„å‘½é¢˜ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹çº¦æŸç”Ÿæˆæ–°çš„é«˜è´¨é‡é¢˜ç›®ï¼š
1ï¸âƒ£ éš¾åº¦ä¸æ ·é¢˜ä¸€è‡´ï¼ˆ{target_difficulty_hint}ï¼‰ï¼Œä¸å¾—ç®€åŒ–é¢˜æ„ã€ç¼©çŸ­ç¯‡å¹…æˆ–é™ä½é€»è¾‘å¤æ‚åº¦ï¼›
2ï¸âƒ£ ç¡®ä¿çŸ¥è¯†ç‚¹è¦†ç›–åˆç†ï¼Œç¬¦åˆä¸“ä¸šè¯¾ç¨‹è€ƒè¯•é£æ ¼ï¼›
3ï¸âƒ£ è¾“å‡ºæ ¼å¼å¿…é¡»ä¸º JSON æ•°ç»„ï¼Œä¸å«é¢å¤–æ–‡å­—ã€‚

ã€å‡ºé¢˜ç›®æ ‡ã€‘
- å½“å‰ç« èŠ‚ï¼š{section['title']}
- å»ºè®®éš¾åº¦æ°´å¹³ï¼š{global_difficulty}
- é¢˜å‹åˆ†å¸ƒå‚è€ƒï¼š{json.dumps(type_info, ensure_ascii=False, indent=2)}
- éš¾åº¦åˆ†å¸ƒå‚è€ƒï¼š{json.dumps(diff_info, ensure_ascii=False, indent=2)}
- çŸ¥è¯†ç‚¹è¦†ç›–å‚è€ƒï¼š{json.dumps(kp_info, ensure_ascii=False, indent=2)}
"""
    if expected_count is not None:
        prompt += f"\nã€æ•°é‡çº¦æŸã€‘æœ¬èŠ‚å¿…é¡»ä¸¥æ ¼ç”Ÿæˆ {expected_count} é“é¢˜ï¼ˆä¸å¤šä¸å°‘ï¼‰ã€‚"
    if expected_type:
        prompt += f"\nã€é¢˜å‹çº¦æŸã€‘æœ¬èŠ‚é¢˜å‹å›ºå®šä¸ºï¼š{expected_type}ï¼ˆæ¯é¢˜ question_type ä¿æŒä¸€è‡´ï¼‰ã€‚"
    if expected_kps:
        prompt += f"\nã€çŸ¥è¯†ç‚¹çº¦æŸã€‘æœ¬èŠ‚ç”Ÿæˆçš„é¢˜ç›®å¿…é¡»æ˜¾å¼è¦†ç›–ä»¥ä¸‹çŸ¥è¯†ç‚¹ï¼š{expected_kps}ã€‚"

    # â€”â€” æ·±åº¦ä¸ç»“æ„è¦æ±‚ï¼ˆå…³é”®ï¼‰â€”â€”
    prompt += f"""
ã€æ·±åº¦ä¸ç»“æ„è¦æ±‚ã€‘
- é¢˜å¹²éœ€åŒ…å«è‡³å°‘ {min_subparts} ä¸ªæœ‰é€’è¿›å…³ç³»çš„å­é—®ï¼ˆ(a)(b)(c) â€¦ï¼‰ï¼Œè¦†ç›–ä¸åŒè§’åº¦ï¼ˆå®šä¹‰/æ¨å¯¼/æ¯”è¾ƒ/åä¾‹/å¤æ‚åº¦/å·¥ç¨‹å–èˆï¼‰ã€‚
- è‡³å°‘åŒ…å«ä¸€æ¬¡â€œå®šé‡è®¡ç®—æˆ–å…¬å¼æ¨å¯¼â€ä¸ä¸€æ¬¡â€œæ–¹æ³•å¯¹æ¯”æˆ–è¾¹ç•Œ/å¼‚å¸¸æƒ…å½¢åˆ†æâ€ã€‚
- å¦‚ä¸ºç»¼åˆ/åº”ç”¨ç±»é¢˜ï¼Œè¦æ±‚è®¾ç½®çœŸå®æ•°æ®ç‰‡æ®µæˆ–è¿‘ä¼¼æ•°æ®ã€å¹¶ç»™å‡ºæ˜ç¡®è®¡ç®—æˆ–åˆ¤æ–­æ­¥éª¤ã€‚
- å¯¹äºé€‰æ‹©é¢˜ï¼Œå¹²æ‰°é¡¹å¿…é¡»åŸºäºå¸¸è§è¯¯åŒºï¼ˆä¸è¦æ˜æ˜¾é”™è¯¯çš„é€‰é¡¹ï¼‰ã€‚

ã€æ ·é¢˜å‚è€ƒã€‘
"""
    if examples:
        example_snippets = []
        for q in examples[:3]:
            # å°†æ ·é¢˜ä¸­çš„HTMLè¡¨æ ¼è½¬æ¢ä¸ºMarkdownï¼Œè®©LLMæ›´å®¹æ˜“ç†è§£å’Œæ¨¡ä»¿
            stem_for_llm = _convert_html_table_to_markdown(q.stem)
            
            snippet = (
                f"é¢˜å¹²ï¼š{stem_for_llm}\n"
                f"ç­”æ¡ˆï¼š{q.answer or 'ï¼ˆæ— ç­”æ¡ˆï¼‰'}\n"
                f"çŸ¥è¯†ç‚¹ï¼š{', '.join(q.knowledge_points)}\n"
                f"éš¾åº¦ï¼š{q.difficulty}\n"
                f"é¢˜å‹ï¼š{q.question_type}\n"
            )
            
            # æ·»åŠ å­é¢˜ç›®ä¿¡æ¯
            sub_qs = q.sub_questions if hasattr(q, 'sub_questions') else []
            if sub_qs:
                snippet += f"å­é¢˜ç›®æ•°é‡ï¼š{len(sub_qs)}\n"
                snippet += f"å­é¢˜ç›®ç»“æ„ï¼š\n{_format_sub_questions(sub_qs)}\n"
            
            example_snippets.append(snippet)
        prompt += "\n---\n".join(example_snippets)

    # âœ… åœ¨è¿™é‡Œæ’å…¥è¯­è¨€çº¦æŸé€»è¾‘
    if expected_language:
        prompt += f"\nã€è¯­è¨€çº¦æŸã€‘é¢˜å¹²ï¼ˆstemï¼‰ã€ç­”æ¡ˆï¼ˆanswerï¼‰ã€è§£æï¼ˆexplanationï¼‰å¿…é¡»ä½¿ç”¨ {expected_language} è¾“å‡ºï¼›" \
                  f"knowledge_points å­—æ®µå¯ä»¥ä½¿ç”¨ä¸­æ–‡ã€‚"

    # æ ¹æ®æ ·é¢˜æ˜¯å¦æœ‰å­é¢˜ç›®ï¼ŒåŠ¨æ€ç”Ÿæˆè¾“å‡ºæ ¼å¼ç¤ºä¾‹
    has_sub_questions = False
    if examples:
        for q in examples[:3]:
            sub_qs = q.sub_questions if hasattr(q, 'sub_questions') else []
            if sub_qs:
                has_sub_questions = True
                break
    
    prompt += """
ã€è¡¨æ ¼æ ¼å¼è¯´æ˜ã€‘
å¦‚æœé¢˜ç›®éœ€è¦åŒ…å«è¡¨æ ¼æ•°æ®ï¼Œè¯·ä½¿ç”¨Markdownè¡¨æ ¼æ ¼å¼ï¼š
| åˆ—1 | åˆ—2 | åˆ—3 |
|-----|-----|-----|
| æ•°æ®1 | æ•°æ®2 | æ•°æ®3 |

ã€è¾“å‡ºæ ¼å¼ç¤ºä¾‹ã€‘
"""
    
    if has_sub_questions:
        prompt += """[
  {
    "stem": "ä¸»é¢˜å¹²æ–‡æœ¬ï¼ˆç®€çŸ­æè¿°é¢˜ç›®èƒŒæ™¯æˆ–æ€»ä½“è¦æ±‚ï¼‰",
    "options": [],
    "answer": "ï¼ˆå¾…è¡¥å……ï¼‰æˆ–ç»¼åˆç­”æ¡ˆè¦ç‚¹",
    "explanation": "æ•´ä½“è§£æè¯´æ˜",
    "difficulty": "easy | medium | hard",
    "knowledge_points": ["æ¶‰åŠçš„çŸ¥è¯†ç‚¹ 1", "çŸ¥è¯†ç‚¹ 2"],
    "question_type": "short_answer | calculation | comprehensive",
    "sub_questions": [
      {
        "label": "a",
        "stem": "å­é—®é¢˜(a)çš„å…·ä½“é¢˜å¹²å†…å®¹",
        "knowledge_points": ["å­é¢˜çŸ¥è¯†ç‚¹"],
        "difficulty": "easy | medium | hard",
        "question_type": "short_answer | calculation",
        "sub_questions": []
      },
      {
        "label": "b",
        "stem": "å­é—®é¢˜(b)çš„å…·ä½“é¢˜å¹²å†…å®¹",
        "knowledge_points": ["å­é¢˜çŸ¥è¯†ç‚¹"],
        "difficulty": "easy | medium | hard",
        "question_type": "calculation",
        "sub_questions": [
          {
            "label": "i",
            "stem": "åµŒå¥—å­é—®é¢˜(i)å†…å®¹",
            "knowledge_points": ["åµŒå¥—å­é¢˜çŸ¥è¯†ç‚¹"],
            "difficulty": "easy",
            "question_type": "short_answer",
            "sub_questions": []
          }
        ]
      }
    ]
  }
]
æ³¨æ„ï¼š
1. å¦‚æœæ ·é¢˜æœ‰å­é¢˜ç›®ç»“æ„ï¼Œç”Ÿæˆçš„é¢˜ç›®ä¹Ÿå¿…é¡»åŒ…å« sub_questions æ•°ç»„
2. æ¯ä¸ªå­é¢˜ç›®å¿…é¡»æœ‰ç‹¬ç«‹çš„ labelï¼ˆå¦‚ a/b/c æˆ– i/ii/iiiï¼‰ã€stemã€knowledge_points
3. å­é¢˜ç›®å¯ä»¥åµŒå¥—ï¼ˆå¦‚ c ä¸‹é¢æœ‰ i/ii/iiiï¼‰
"""
    else:
        prompt += """[
  {
    "stem": "é¢˜å¹²æ–‡æœ¬",
    "options": ["A. ...", "B. ...", "C. ...", "D. ..."],
    "answer": "æ­£ç¡®ç­”æ¡ˆæˆ–è¦ç‚¹",
    "explanation": "ç®€è¦è¯´æ˜æ­£ç¡®åŸå› ",
    "difficulty": "easy | medium | hard",
    "knowledge_points": ["æ¶‰åŠçš„çŸ¥è¯†ç‚¹ 1", "çŸ¥è¯†ç‚¹ 2"],
    "question_type": "single_choice | short_answer | calculation"
  }
]
"""
    
    prompt += "åªè¾“å‡º JSONï¼Œä¸è¦æ·»åŠ è§£é‡Šæˆ–å…¶ä»–è‡ªç„¶è¯­è¨€ã€‚\n"
    return prompt



# -----------------------------------------------------------
# è°ƒç”¨ LLM å¼‚æ­¥ç”Ÿæˆ
# -----------------------------------------------------------

async def async_generate_section(session, section, distribution_model, examples=None, global_difficulty="medium"):
    # æœŸæœ›é¢˜æ•°
    expected_count = None
    try:
        ranges = section.get("question_ranges", [])
        expected_count = sum(r.get("to", 0) - r.get("from", 0) + 1 for r in ranges if r)
    except Exception:
        pass

    # æœŸæœ›é¢˜å‹ï¼ˆæ¥è‡ªæ ‡é¢˜ â€œâ€¦ Sectionâ€ï¼‰
    expected_type = None
    title = section.get("title") or ""
    if isinstance(title, str) and title.endswith(" Section"):
        expected_type = title[:-8]

    # æ¨¡æ¿çŸ¥è¯†ç‚¹ä¸éš¾åº¦æç¤ºï¼ˆåœ¨ run_agent_e é‡Œè®¾ç½®è¿› sectionï¼‰
    expected_kps = section.get("expected_kps")
    target_difficulty_hint = section.get("target_difficulty_hint", "ä¿æŒä¸æ ·ä¾‹ç›¸åŒå±‚çº§ï¼Œä½†åœ¨æ·±åº¦ä¸ç»¼åˆæ€§ä¸Šæé«˜")

    # ğŸ†• æ ¹æ® question_ranges é€‰æ‹©å¯¹åº”çš„ examples
    section_examples = examples  # é»˜è®¤ä½¿ç”¨å…¨éƒ¨ examples
    if examples and len(examples) > 0:
        try:
            ranges = section.get("question_ranges", [])
            if ranges and len(ranges) > 0:
                # è·å–ç¬¬ä¸€ä¸ª range çš„èµ·å§‹ä½ç½®ï¼ˆ1-based indexï¼‰
                start_idx = ranges[0].get("from", 1) - 1  # è½¬æ¢ä¸º 0-based
                end_idx = ranges[0].get("to", 1)  # inclusive
                section_examples = examples[start_idx:end_idx]
                print(f"[ğŸ“Œ Section] ä½¿ç”¨ examples[{start_idx}:{end_idx}]ï¼Œå…± {len(section_examples)} é“é¢˜")
        except Exception as e:
            print(f"[âš ï¸ é€‰æ‹© section examples å¤±è´¥] {e}")

    prompt = build_prompt(
        section, distribution_model, section_examples, global_difficulty,
        expected_count=expected_count, expected_type=expected_type,
        expected_kps=expected_kps, target_difficulty_hint=target_difficulty_hint,
        min_subparts=2, expected_language=section.get("expected_language")
    )

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åé«˜çº§è€ƒè¯•å‘½é¢˜ä¸“å®¶ï¼Œæ“…é•¿ç”Ÿæˆå°ºåº¦æ°å½“ä¸”è¦†ç›–å…¨é¢çš„æ·±åº¦è¯•é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 4000,   # â†‘ ç•¥å¢
        "temperature": 0.6,   # â†“ ç•¥é™ï¼Œæå‡ç¨³å®šåº¦ä¸å¯¹é½åº¦
        "top_p": 0.95,
    }

    # è·å– conversation_id ç”¨äºä¿å­˜ debug æ–‡ä»¶
    conv_id = section.get("_conversation_id", "unknown")
    section_title = section.get("title", "unknown").replace(" ", "_")
    
    try:
        async with session.post(f"{API_URL}/chat/completions", headers=HEADERS, json=payload, timeout=240) as resp:
            res = await resp.json()
            content = res["choices"][0]["message"]["content"]
            
            # ä¿å­˜ LLM åŸå§‹å“åº”åˆ° debug ç›®å½•
            _save_llm_response(conv_id, section_title, prompt, content)
            
            items = _extract_json_array(content)

            # å°†LLMç”Ÿæˆçš„Markdownè¡¨æ ¼è½¬æ¢ä¸ºHTMLè¡¨æ ¼
            for item in items:
                if 'stem' in item and item['stem']:
                    item['stem'] = _convert_markdown_table_to_html(item['stem'])
                if 'answer' in item and item['answer']:
                    item['answer'] = _convert_markdown_table_to_html(item['answer'])
                if 'explanation' in item and item['explanation']:
                    item['explanation'] = _convert_markdown_table_to_html(item['explanation'])

            # ğŸ†• ä¸ºåŒ…å«è¡¨æ ¼çš„é¢˜ç›®ç”Ÿæˆç­”æ¡ˆ
            for idx, item in enumerate(items, 1):
                stem = item.get('stem', '')
                answer = item.get('answer', '')
                # å¦‚æœé¢˜å¹²åŒ…å«è¡¨æ ¼ä¸”ç­”æ¡ˆä¸ºç©ºæˆ–ä¸ºå¾…è¡¥å……ï¼Œåˆ™ç”Ÿæˆç­”æ¡ˆ
                if '<table' in stem and (not answer or answer == 'ï¼ˆå¾…è¡¥å……ï¼‰'):
                    question_id = f"{section.get('title', 'Q')}_{idx}"
                    generated_answer = await _generate_answer_for_table_question(session, question_id, stem)
                    if generated_answer:
                        item['answer'] = generated_answer

            # è¶…é¢è£å‰ªï¼ˆä¸è¶³ä¸åšäºŒæ¬¡é‡è¯•ï¼Œä¿æŒæœ€å°æ”¹åŠ¨ç­–ç•¥ï¼‰
            if expected_count is not None and len(items) > expected_count:
                items = items[:expected_count]
            return items
    except Exception as e:
        print(f"[âŒ LLM ç”Ÿæˆå¤±è´¥] section={section.get('title', 'unknown')}, error={e}")
        print(f"[ğŸ”„ ä½¿ç”¨é™çº§æ–¹æ¡ˆ] åŸºäºå½“å‰ section çš„æ ·ä¾‹é¢˜ç›®ç”Ÿæˆ")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æ ·ä¾‹é¢˜ç›®æˆ–ç”Ÿæˆç®€å•é¢˜ç›®
        fallback_questions = []
        
        # ğŸ†• ä½¿ç”¨ section_examples è€Œä¸æ˜¯ examplesï¼ˆç¡®ä¿æ¯ä¸ª section ç”¨ä¸åŒçš„é¢˜ç›®ï¼‰
        if section_examples and len(section_examples) > 0:
            for idx, example in enumerate(section_examples[:expected_count or 1], 1):
                q_dict = example.dict() if hasattr(example, 'dict') else example
                fallback_questions.append({
                    "stem": q_dict.get('stem', f"ç¤ºä¾‹é¢˜ç›® {idx}"),
                    "options": q_dict.get('options', []),
                    "answer": q_dict.get('answer', 'å‚è€ƒç­”æ¡ˆ'),
                    "explanation": q_dict.get('explanation', 'è¯¦è§æ•™æ'),
                    "difficulty": global_difficulty,
                    "knowledge_points": q_dict.get('knowledge_points', ['é€šç”¨çŸ¥è¯†']),
                    "question_type": q_dict.get('question_type', 'short_answer')
                })
        else:
            # ç”Ÿæˆé»˜è®¤é¢˜ç›®
            for i in range(expected_count or 3):
                fallback_questions.append({
                    "stem": f"è¯·ç®€è¿°{section.get('name', 'ç›¸å…³')}çš„ä¸»è¦æ¦‚å¿µã€‚",
                    "options": [],
                    "answer": "è¯·å‚è€ƒæ•™æç›¸å…³ç« èŠ‚ã€‚",
                    "explanation": "æœ¬é¢˜è€ƒæŸ¥åŸºç¡€æ¦‚å¿µç†è§£ã€‚",
                    "difficulty": global_difficulty,
                    "knowledge_points": [section.get('name', 'é€šç”¨çŸ¥è¯†')],
                    "question_type": "short_answer"
                })
        
        print(f"[âœ… é™çº§æ–¹æ¡ˆç”Ÿæˆ] {len(fallback_questions)} é“é¢˜ç›®")
        return fallback_questions



# -----------------------------------------------------------
# ä¸»å‡½æ•°
# -----------------------------------------------------------

def run_agent_e(conversation_id: str):
    print("ğŸ§© [Agent E] é«˜ä¿çœŸæ™ºèƒ½å‡ºé¢˜ç”Ÿæˆå¼€å§‹...")

    qb = shared_state.question_bank
    dist_model = shared_state.distribution_model
    structure_model = getattr(shared_state, "sample_structure", None)

    if not dist_model:
        print("âš ï¸ ç¼ºå°‘ Agent C è¾“å‡ºï¼Œæ— æ³•ç”Ÿæˆåˆ†å¸ƒæ¨¡å‹ã€‚")
        return None

    # â€”â€” è‹¥å­˜åœ¨æ¨¡æ¿é¢˜åº“ï¼šé€é¢˜å»ºæ®µï¼ˆé¡ºåºå¯¹é½ + é¢˜å‹å¯¹é½ + çŸ¥è¯†ç‚¹å¯¹é½ï¼‰â€”â€”
    if qb and getattr(qb, "questions", None):
        sections = []
        TYPE_TITLE_EN = {
            "ç®€ç­”é¢˜": "Short Answer",
            "ç»¼åˆé¢˜": "Comprehensive",
            "ç»¼åˆåˆ†æé¢˜": "Comprehensive",
            "ç®—æ³•åº”ç”¨é¢˜": "Applied Algorithms",
            "è®¡ç®—é¢˜": "Problem Solving",
        }
        for idx, tq in enumerate(qb.questions, start=1):
            t = (tq.question_type or "short_answer")
            # æ ‡é¢˜è‹±æ–‡åŒ–ï¼Œé¿å…ä¸­è‹±æ··æ’å¹²æ‰°æ¨¡å‹è¯­è¨€é€‰æ‹©
            title_en = TYPE_TITLE_EN.get(t, t if _has_cjk(t) is False else "Section")
            expected_language = _detect_language_from_stem(getattr(tq, "stem", "") or "")
            sections.append({
                "title": f"{title_en} Section_{idx}",
                "question_ranges": [{"from": idx, "to": idx}],
                "score": None,
                "expected_kps": tq.knowledge_points if getattr(tq, "knowledge_points", None) else None,
                "target_difficulty_hint": "ä¿æŒä¸æ ·ä¾‹ç›¸åŒå±‚çº§ï¼Œä½†åœ¨æ·±åº¦ä¸ç»¼åˆæ€§ä¸Šæé«˜",
                "expected_language": expected_language,
                "_conversation_id": conversation_id,  # ç”¨äºä¿å­˜ debug æ–‡ä»¶
            })
        structure_model = {"sections": sections}
    else:
        # æ— æ¨¡æ¿åˆ™ä¿ç•™ä½ çš„åŸå…œåº•ï¼Œé¡ºä¾¿ä¿®è¡¥"sections ä¸ºç©ºä¹Ÿè§†ä¸ºæ— æ•ˆç»“æ„"
        if (not structure_model
            or structure_model.get("section_count", 0) == 0
            or not structure_model.get("sections")):
            print("âš ï¸ æ— æœ‰æ•ˆæ ·ä¾‹ç»“æ„ï¼Œä½¿ç”¨ Agent C çš„é¢˜å‹æ¯”ä¾‹ç”Ÿæˆè™šæ‹Ÿç« èŠ‚ã€‚")
            type_dist = dist_model.get("type_distribution", {})
            sections = []
            q_start = 1
            total_questions = dist_model.get("total_questions", 10)
            for t, ratio in type_dist.items():
                count = max(1, int(total_questions * ratio))
                q_end = q_start + count - 1
                sections.append({
                    "title": f"{t} Section",
                    "question_ranges": [{"from": q_start, "to": q_end}],
                    "score": None,
                    "_conversation_id": conversation_id,
                })
                q_start = q_end + 1
            structure_model = {"sections": sections}

    # è‡ªåŠ¨æ£€æµ‹å…¨å±€éš¾åº¦ï¼ˆä¿æŒä¸å˜ï¼‰
    if qb and getattr(qb, "questions", None):
        difficulties = [q.difficulty for q in qb.questions if q.difficulty]
        global_difficulty = max(set(difficulties), key=difficulties.count) if difficulties else "medium"
    else:
        global_difficulty = "medium"

    print(f"ğŸ‘‰ æ£€æµ‹åˆ°æ•´ä½“éš¾åº¦ï¼š{global_difficulty}")

    async def main():
        async with aiohttp.ClientSession() as session:
            tasks = [
                async_generate_section(session, section, dist_model, qb.questions if qb else None, global_difficulty)
                for section in structure_model["sections"]
            ]
            return await asyncio.gather(*tasks)

    all_sections = asyncio.run(main())

    # åˆå¹¶ç”Ÿæˆé¢˜ç›®
    generated_questions = []
    for sec in all_sections:
        for item in sec:
            try:
                # è§£æå­é¢˜ç›®
                sub_questions = _parse_sub_questions_from_dict(item.get("sub_questions", []))
                
                q = Question(
                    id=f"GEN_{len(generated_questions)+1:03d}",
                    stem=item.get("stem"),
                    options=item.get("options", []),
                    answer=item.get("answer"),
                    explanation=item.get("explanation"),
                    difficulty=item.get("difficulty", "medium"),
                    knowledge_points=item.get("knowledge_points", ["é€šç”¨çŸ¥è¯†"]),
                    question_type=item.get("question_type", "short_answer"),
                    sub_questions=sub_questions
                )
                generated_questions.append(q)
                
                if sub_questions:
                    print(f"[âœ“] é¢˜ç›® {q.id} åŒ…å« {len(sub_questions)} ä¸ªå­é¢˜ç›®")
            except Exception as e:
                print(f"[âš ï¸ é¢˜ç›®è§£æå¼‚å¸¸] {e}")

    new_qb = QuestionBank(questions=generated_questions)
    shared_state.generated_exam = new_qb

    save_path = save_question_bank(f"{conversation_id}_generated", new_qb)
    print(f"âœ… é«˜ä¿çœŸ Agent E å®Œæˆï¼Œå…±ç”Ÿæˆ {len(generated_questions)} é¢˜ã€‚")
    print(f"ğŸ’¾ é¢˜åº“ä¿å­˜è·¯å¾„ï¼š{save_path}")
    return new_qb



